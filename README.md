## Short repo description  
This repo is about using Machine learning to recognise a set of hand gestures and use those to interact with youtube player.  
The project falls within the area of gesture-based user-interfaces. These systems can for example:  
* help people with disabilities to easily interact with a wide range of devices, which increases their autonomy and independency;
* contribute to reduce the widespread of contagious diseases such as corona through the implementation of contactless devices;
* improve user-experience, because gesture-based interfaces are most of the time more intuitive and easier to learn.  

The interactions that were implemented are:  
* simple virtual mouse functionalities (move, left and right click);
* play and pause the video;
* increase and decrease the volume of both the media player and computer;
* forward and backward jumps;
* activate and deactivate fullscreen mode;
* activate and deactivate subtitles/ closed captions, when these are available;
* additionally, if user is sleeping or has left, automatically pause the video.  

All feedbacks on what can be improved are welcome :)
 
