This repo is about using Machine learning to recognise a set of hand gestures and use those to interact with youtube player.  
The project falls within the area of gesture-based user-interfaces. These systems can for example:  
* help people with disabilities to easily interact with a wide range of devices and by this mean make them feel more autonomous and indepedent;
* contribute to reduce the widespread of contagious diseases such as corona through the implementation of contactless devices;
* improves user-experience, because gesture-based interfaces are most the time more intuitive and easier to learn.  

The interactions that will be implemented are:  
* simple virtual mouse functionalities (move, left and right click);
* play and pause the video;
* increase and decrease the volume of both the media player and computer;
* forward and backward jumps;
* activate and deactivate fullscreen mode;
* save the video link for watching later;
* additionally, if user is sleeping or has left, automatically pause the video.  

I will post very soon pictures of the corresponding gestures and a short demo video :)
 
